"""
Layer 4: EXTERNAL SEARCH LAYER
web_search_agentë¥¼ ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤, íˆ¬ììœ ì¹˜ ì •ë³´, ì‹¤ì‹œê°„ ì§€í‘œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë ˆì´ì–´
"""
import asyncio
import aiohttp
import requests
import os
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import re
from serpapi import GoogleSearch

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import ExternalSearchResult, PipelineContext
from config import get_config

class WebSearchAgent:
    """ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸"""

    def __init__(self):
        self.config = get_config()
        self.session = None

    async def search_company_news(self, company_name: str, days_back: int = None) -> List[ExternalSearchResult]:
        """íšŒì‚¬ ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰"""
        if days_back is None:
            days_back = int(os.getenv("NEWS_SEARCH_DAYS_BACK", "730"))
        
        print(f"ğŸ” COMPANY_NEWS_SEARCH - {company_name} (ìµœê·¼ {days_back}ì¼)")
        print("=" * 60)
        
        results = []

        # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
        print(f"ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘...")
        naver_results = await self._search_naver_news(company_name, days_back)
        print(f"ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(naver_results)}ê°œ ê²°ê³¼")
        for i, result in enumerate(naver_results, 1):
            print(f"  {i}. {result.title} ({result.source}) - {result.relevance_score:.2f}")
        results.extend(naver_results)

        # êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰
        print(f"ğŸŒ êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘...")
        google_results = await self._search_google_news(company_name, days_back)
        print(f"ğŸŒ êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(google_results)}ê°œ ê²°ê³¼")
        for i, result in enumerate(google_results, len(naver_results) + 1):
            print(f"  {i}. {result.title} ({result.source}) - {result.relevance_score:.2f}")
        results.extend(google_results)

        print(f"ğŸ“Š ì´ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        print("=" * 60)
        return results

    async def search_investment_info(self, company_name: str) -> List[ExternalSearchResult]:
        """íˆ¬ììœ ì¹˜ ì •ë³´ ê²€ìƒ‰"""
        print(f"ğŸ’° INVESTMENT_INFO_SEARCH - {company_name}")
        print("=" * 60)
        
        results = []

        # í¬ëŸ°ì¹˜ë² ì´ìŠ¤ ìŠ¤íƒ€ì¼ ê²€ìƒ‰
        print(f"ğŸ“Š íˆ¬ì ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹œì‘...")
        investment_results = await self._search_investment_databases(company_name)
        print(f"ğŸ“Š íˆ¬ì ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(investment_results)}ê°œ ê²°ê³¼")
        for i, result in enumerate(investment_results, 1):
            print(f"  {i}. {result.title} ({result.source}) - {result.relevance_score:.2f}")
        results.extend(investment_results)

        # ë²¤ì²˜ íˆ¬ì ë‰´ìŠ¤ ê²€ìƒ‰
        print(f"ğŸš€ ë²¤ì²˜ íˆ¬ì ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘...")
        venture_results = await self._search_venture_news(company_name)
        print(f"ğŸš€ ë²¤ì²˜ íˆ¬ì ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(venture_results)}ê°œ ê²°ê³¼")
        for i, result in enumerate(venture_results, len(investment_results) + 1):
            print(f"  {i}. {result.title} ({result.source}) - {result.relevance_score:.2f}")
        results.extend(venture_results)

        print(f"ğŸ“Š ì´ íˆ¬ì ì •ë³´ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        print("=" * 60)
        return results

    async def search_market_indicators(self, company_name: str) -> List[ExternalSearchResult]:
        """ì‹¤ì‹œê°„ ì‹œì¥ ì§€í‘œ ê²€ìƒ‰ (ì£¼ê°€, ë°¸ë¥˜ì—ì´ì…˜ ë“±)"""
        print(f"ğŸ“ˆ MARKET_INDICATORS_SEARCH - {company_name}")
        print("=" * 60)
        
        results = []

        # ì£¼ê°€ ì •ë³´ ê²€ìƒ‰
        print(f"ğŸ“Š ì£¼ê°€ ì •ë³´ ê²€ìƒ‰ ì‹œì‘...")
        stock_results = await self._search_stock_info(company_name)
        print(f"ğŸ“Š ì£¼ê°€ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ: {len(stock_results)}ê°œ ê²°ê³¼")
        for i, result in enumerate(stock_results, 1):
            print(f"  {i}. {result.title} ({result.source}) - {result.relevance_score:.2f}")
        results.extend(stock_results)

        # ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´ ê²€ìƒ‰
        print(f"ğŸ’ ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´ ê²€ìƒ‰ ì‹œì‘...")
        valuation_results = await self._search_valuation_info(company_name)
        print(f"ğŸ’ ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ: {len(valuation_results)}ê°œ ê²°ê³¼")
        for i, result in enumerate(valuation_results, len(stock_results) + 1):
            print(f"  {i}. {result.title} ({result.source}) - {result.relevance_score:.2f}")
        results.extend(valuation_results)

        print(f"ğŸ“Š ì´ ì‹œì¥ ì§€í‘œ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        print("=" * 60)
        return results

    async def _search_naver_news(self, company_name: str, days_back: int) -> List[ExternalSearchResult]:
        """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ (ë„¤ì´ë²„ API ì§ì ‘ ì‚¬ìš©)"""
        results = []
        try:
            # ë„¤ì´ë²„ API í‚¤ í™•ì¸
            naver_client_id = os.getenv("NAVER_CLIENT_ID")
            naver_client_secret = os.getenv("NAVER_CLIENT_SECRET")
            
            if not naver_client_id or not naver_client_secret:
                print(f"  âŒ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ (NAVER_CLIENT_ID, NAVER_CLIENT_SECRET)")
                return results

            search_query = f"{company_name} íˆ¬ì"
            print(f"  ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ ì¿¼ë¦¬: '{search_query}'")
            print(f"  ğŸ“… ê²€ìƒ‰ ê¸°ê°„: ìµœê·¼ 2ë…„")

            # ë„¤ì´ë²„ ë‰´ìŠ¤ API ì§ì ‘ í˜¸ì¶œ
            url = f"https://openapi.naver.com/v1/search/news.json?query={search_query}&display=20&sort=sim"
            headers = {
                'X-Naver-Client-Id': naver_client_id,
                'X-Naver-Client-Secret': naver_client_secret
            }

            print(f"  ğŸ”§ ë„¤ì´ë²„ API URL: {url}")

            response = requests.get(url, headers=headers)
            result = response.json()
            
            print(f"  ğŸ“Š ë„¤ì´ë²„ API ì‘ë‹µ ìƒíƒœ: {response.status_code}")

            # ì˜¤ë¥˜ ì²´í¬
            if response.status_code != 200:
                print(f"  âŒ ë„¤ì´ë²„ API ì˜¤ë¥˜: {result}")
                return results

            # ê²°ê³¼ ìœ íš¨ì„± ì²´í¬
            if "items" not in result or not result["items"]:
                print(f"  âš ï¸ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return results

            for item in result["items"]:
                try:
                    title = item.get("title", "").replace("<b>", "").replace("</b>", "")
                    url = item.get("link", "")
                    description = item.get("description", "").replace("<b>", "").replace("</b>", "")
                    pub_date = item.get("pubDate", "")
                    
                    print(f"  ğŸ“° ê¸°ì‚¬: {title[:50]}...")
                    
                    # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                    relevance_score = self._calculate_relevance_score(title + " " + description, company_name)
                    
                    if relevance_score > 0.3:  # ìµœì†Œ ê´€ë ¨ì„± ì„ê³„ê°’
                        external_result = ExternalSearchResult(
                            title=title,
                            content=description,
                            source="ë„¤ì´ë²„ ë‰´ìŠ¤",
                            url=url,
                            published_date=datetime.now(),
                            relevance_score=relevance_score
                        )
                        results.append(external_result)
                except Exception as e:
                    print(f"  âŒ ê¸°ì‚¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue

            print(f"  âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê¸°ì‚¬")

        except Exception as e:
            print(f"  âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return results

    async def _search_google_news(self, company_name: str, days_back: int) -> List[ExternalSearchResult]:
        """êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ (SERPAPI ì‚¬ìš©)"""
        results = []
        try:
            serpapi_key = os.getenv("SERPAPI_API_KEY")
            if not serpapi_key:
                print(f"  âŒ SERPAPI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return results

            search_query = f"{company_name} investment"
            print(f"  ğŸ” êµ¬ê¸€ ê²€ìƒ‰ ì¿¼ë¦¬: '{search_query}'")

            # SERPAPIë¥¼ ì‚¬ìš©í•œ êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ (ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬)
            params = {
                "engine": "google",
                "q": search_query,
                "tbm": "nws",  # ë‰´ìŠ¤ ê²€ìƒ‰
                "hl": "ko",
                "gl": "kr",
                "api_key": serpapi_key,
                "num": 10,  # ê²°ê³¼ ìˆ˜ ì¤„ì„
                "tbs": "qdr:y2"  # ìµœê·¼ 2ë…„ ë²”ìœ„ ê³ ì •
            }
            
            print(f"  ğŸ”§ SERPAPI íŒŒë¼ë¯¸í„°: {params}")

            search = GoogleSearch(params)
            search_results = search.get_dict()
            
            print(f"  ğŸ“Š SERPAPI ì‘ë‹µ í‚¤: {list(search_results.keys())}")

            # ì˜¤ë¥˜ ì²´í¬
            if "error" in search_results:
                print(f"  âŒ SERPAPI ì˜¤ë¥˜: {search_results['error']}")
                return results

            # ê²°ê³¼ ìœ íš¨ì„± ì²´í¬
            if "news_results" not in search_results or not search_results["news_results"]:
                print(f"  âš ï¸ êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return results

            for result in search_results["news_results"]:
                try:
                    title = result.get("title", "")
                    url = result.get("link", "")
                    snippet = result.get("snippet", "")
                    source = result.get("source", "Google News")
                    
                    print(f"  ğŸ“° ê¸°ì‚¬: {title[:50]}...")
                    
                    # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                    relevance_score = self._calculate_relevance_score(title + " " + snippet, company_name)
                    
                    if relevance_score > 0.3:  # ìµœì†Œ ê´€ë ¨ì„± ì„ê³„ê°’
                        external_result = ExternalSearchResult(
                            title=title,
                            content=snippet,
                            source=source,
                            url=url,
                            published_date=datetime.now(),
                            relevance_score=relevance_score
                        )
                        results.append(external_result)
                except Exception as e:
                    print(f"  âŒ ê¸°ì‚¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue

            print(f"  âœ… êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê¸°ì‚¬")

        except Exception as e:
            print(f"  âŒ êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return results

    async def _search_investment_databases(self, company_name: str) -> List[ExternalSearchResult]:
        """íˆ¬ì ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ (SERPAPI ì‚¬ìš©)"""
        results = []
        try:
            serpapi_key = os.getenv("SERPAPI_API_KEY")
            if not serpapi_key:
                print(f"    âŒ SERPAPI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return results

            print(f"    ğŸ” íˆ¬ì ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹œì‘: {company_name}")
            
            # í•œêµ­ íˆ¬ì ê´€ë ¨ ê²€ìƒ‰ (ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬)
            print(f"    ğŸ‡°ğŸ‡· í•œêµ­ íˆ¬ì ì •ë³´ ê²€ìƒ‰...")
            korean_query = f"{company_name} íˆ¬ì"
            korean_results = await self._search_with_serpapi(korean_query, serpapi_key, "í•œêµ­ íˆ¬ì")
            print(f"    ğŸ‡°ğŸ‡· í•œêµ­ íˆ¬ì ì •ë³´ ê²°ê³¼: {len(korean_results)}ê°œ")
            results.extend(korean_results)

            # ê¸€ë¡œë²Œ íˆ¬ì ê´€ë ¨ ê²€ìƒ‰ (ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬)
            print(f"    ğŸŒ ê¸€ë¡œë²Œ íˆ¬ì ì •ë³´ ê²€ìƒ‰...")
            global_query = f"{company_name} funding"
            global_results = await self._search_with_serpapi(global_query, serpapi_key, "ê¸€ë¡œë²Œ íˆ¬ì")
            print(f"    ğŸŒ ê¸€ë¡œë²Œ íˆ¬ì ì •ë³´ ê²°ê³¼: {len(global_results)}ê°œ")
            results.extend(global_results)

        except Exception as e:
            print(f"    âŒ íˆ¬ì ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return results

    async def _search_with_serpapi(self, query: str, api_key: str, source_name: str) -> List[ExternalSearchResult]:
        """SERPAPIë¥¼ ì‚¬ìš©í•œ ì¼ë°˜ ê²€ìƒ‰"""
        results = []
        try:
            params = {
                "engine": "google",
                "q": query,
                "hl": "ko",
                "gl": "kr",
                "api_key": api_key,
                "num": 5,  # ê²°ê³¼ ìˆ˜ ë” ì¤„ì„
                "tbs": "qdr:y2"  # ìµœê·¼ 2ë…„ ë²”ìœ„ ê³ ì •
            }
            
            print(f"      ğŸ”§ {source_name} SERPAPI íŒŒë¼ë¯¸í„°: {params}")

            search = GoogleSearch(params)
            search_results = search.get_dict()
            
            print(f"      ğŸ“Š {source_name} SERPAPI ì‘ë‹µ í‚¤: {list(search_results.keys())}")

            # ì˜¤ë¥˜ ì²´í¬
            if "error" in search_results:
                print(f"      âŒ {source_name} SERPAPI ì˜¤ë¥˜: {search_results['error']}")
                return results

            # ê²°ê³¼ ìœ íš¨ì„± ì²´í¬
            if "organic_results" not in search_results or not search_results["organic_results"]:
                print(f"      âš ï¸ {source_name} ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return results

            for result in search_results["organic_results"]:
                try:
                    title = result.get("title", "")
                    url = result.get("link", "")
                    snippet = result.get("snippet", "")
                    
                    print(f"      ğŸ“° {source_name} ê²°ê³¼: {title[:50]}...")
                    
                    # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                    relevance_score = self._calculate_relevance_score(title + " " + snippet, query)
                    
                    if relevance_score > 0.3:  # ìµœì†Œ ê´€ë ¨ì„± ì„ê³„ê°’
                        external_result = ExternalSearchResult(
                            title=title,
                            content=snippet,
                            source=source_name,
                            url=url,
                            published_date=datetime.now(),
                            relevance_score=relevance_score
                        )
                        results.append(external_result)
                except Exception as e:
                    print(f"      âŒ {source_name} ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            print(f"      âŒ {source_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return results

    async def _search_venture_news(self, company_name: str) -> List[ExternalSearchResult]:
        """ë²¤ì²˜ íˆ¬ì ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ (SERPAPI ì‚¬ìš©)"""
        results = []
        try:
            serpapi_key = os.getenv("SERPAPI_API_KEY")
            if not serpapi_key:
                print(f"    âŒ SERPAPI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return results

            # ë‹¨ìˆœí™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬
            print(f"    ğŸš€ ë²¤ì²˜ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘: {company_name}")
            
            # ì¼ë°˜ì ì¸ ë²¤ì²˜ ë‰´ìŠ¤ ê²€ìƒ‰ (ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬)
            query = f"{company_name} ë²¤ì²˜"
            source_results = await self._search_with_serpapi(query, serpapi_key, "ë²¤ì²˜ ë‰´ìŠ¤")
            results.extend(source_results)
            print(f"    ğŸš€ ë²¤ì²˜ ë‰´ìŠ¤ ê²°ê³¼: {len(source_results)}ê°œ")

        except Exception as e:
            print(f"    âŒ ë²¤ì²˜ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return results


    async def _search_stock_info(self, company_name: str) -> List[ExternalSearchResult]:
        """ì£¼ê°€ ì •ë³´ ê²€ìƒ‰ (SERPAPI ì‚¬ìš©)"""
        results = []
        try:
            serpapi_key = os.getenv("SERPAPI_API_KEY")
            if not serpapi_key:
                print(f"    âŒ SERPAPI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return results

            print(f"    ğŸ“Š ì£¼ê°€ ì •ë³´ ê²€ìƒ‰ ì‹œì‘: {company_name}")
            
            # ì£¼ê°€ ê´€ë ¨ ê²€ìƒ‰ (ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬)
            stock_query = f"{company_name} ì£¼ê°€"
            stock_results = await self._search_with_serpapi(stock_query, serpapi_key, "ì£¼ê°€ ì •ë³´")
            results.extend(stock_results)
            print(f"    ğŸ“Š ì£¼ê°€ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ: {len(stock_results)}ê°œ")

        except Exception as e:
            print(f"    âŒ ì£¼ê°€ ì •ë³´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return results

    async def _search_valuation_info(self, company_name: str) -> List[ExternalSearchResult]:
        """ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´ ê²€ìƒ‰ (SERPAPI ì‚¬ìš©)"""
        results = []
        try:
            serpapi_key = os.getenv("SERPAPI_API_KEY")
            if not serpapi_key:
                print(f"    âŒ SERPAPI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return results

            print(f"    ğŸ’ ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´ ê²€ìƒ‰ ì‹œì‘: {company_name}")
            
            # ë°¸ë¥˜ì—ì´ì…˜ ê´€ë ¨ ê²€ìƒ‰ (ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬)
            valuation_query = f"{company_name} ê¸°ì—…ê°€ì¹˜"
            valuation_results = await self._search_with_serpapi(valuation_query, serpapi_key, "ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´")
            results.extend(valuation_results)
            print(f"    ğŸ’ ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ: {len(valuation_results)}ê°œ")

        except Exception as e:
            print(f"    âŒ ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return results


    def _calculate_relevance_score(self, text: str, company_name: str) -> float:
        """í…ìŠ¤íŠ¸ì™€ íšŒì‚¬ëª…ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        text_lower = text.lower()
        company_lower = company_name.lower()

        score = 0.0

        # íšŒì‚¬ëª… ì§ì ‘ ì–¸ê¸‰
        if company_lower in text_lower:
            score += 0.5

        # íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ
        investment_keywords = ["íˆ¬ì", "í€ë”©", "ìœ ì¹˜", "íˆ¬ììœ ì¹˜", "ì‹œë¦¬ì¦ˆ", "ë¼ìš´ë“œ", "ë°¸ë¥˜ì—ì´ì…˜"]
        for keyword in investment_keywords:
            if keyword in text_lower:
                score += 0.1

        # ìŠ¤íƒ€íŠ¸ì—… ê´€ë ¨ í‚¤ì›Œë“œ
        startup_keywords = ["ìŠ¤íƒ€íŠ¸ì—…", "ë²¤ì²˜", "ì°½ì—…", "ê¸°ì—…", "ì‚¬ì—…"]
        for keyword in startup_keywords:
            if keyword in text_lower:
                score += 0.05

        return min(score, 1.0)


class ExternalSearchLayer:
    """ì™¸ë¶€ ê²€ìƒ‰ ë ˆì´ì–´ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.web_search_agent = WebSearchAgent()

    async def search_external_sources(
        self,
        company_name: str,
        search_types: List[str] = None
    ) -> List[ExternalSearchResult]:
        """ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ì¢…í•© ê²€ìƒ‰"""

        if search_types is None:
            search_types = ["news", "investment", "market_indicators"]

        print(f"ğŸŒ EXTERNAL_SEARCH_LAYER - {company_name}")
        print(f"ğŸ” ê²€ìƒ‰ íƒ€ì…: {search_types}")
        print("=" * 60)

        all_results = []

        # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
        tasks = []

        if "news" in search_types:
            tasks.append(self.web_search_agent.search_company_news(company_name))

        if "investment" in search_types:
            tasks.append(self.web_search_agent.search_investment_info(company_name))

        if "market_indicators" in search_types:
            tasks.append(self.web_search_agent.search_market_indicators(company_name))

        print(f"ğŸ“‹ ì´ {len(tasks)}ê°œ ê²€ìƒ‰ ì‘ì—… ì‹œì‘...")

        # ëª¨ë“  ê²€ìƒ‰ ì‘ì—… ì‹¤í–‰
        if tasks:
            search_results = await asyncio.gather(*tasks, return_exceptions=True)

            for i, result in enumerate(search_results, 1):
                if isinstance(result, list):
                    all_results.extend(result)
                    print(f"ğŸ“‹ ì‘ì—… {i} ì™„ë£Œ: {len(result)}ê°œ ê²°ê³¼")
                else:
                    print(f"âŒ ì‘ì—… {i} ì‹¤íŒ¨: {result}")

        print(f"ğŸ“Š ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {len(all_results)}ê°œ")

        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_results = self._deduplicate_results(all_results)
        print(f"ğŸ”„ ì¤‘ë³µ ì œê±° í›„: {len(unique_results)}ê°œ")
        
        sorted_results = sorted(unique_results, key=lambda x: x.relevance_score, reverse=True)
        print(f"ğŸ“ˆ ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ ì™„ë£Œ")

        max_results = int(os.getenv("MAX_EXTERNAL_RESULTS", "20"))
        final_results = sorted_results[:max_results]
        
        print(f"ğŸ“Š ìµœì¢… ë°˜í™˜ ê²°ê³¼: {len(final_results)}ê°œ (ìƒìœ„ {max_results}ê°œ)")
        print("=" * 60)
        
        return final_results

    def _deduplicate_results(self, results: List[ExternalSearchResult]) -> List[ExternalSearchResult]:
        """ì¤‘ë³µ ê²°ê³¼ ì œê±°"""
        seen_urls = set()
        unique_results = []

        for result in results:
            if result.url not in seen_urls:
                seen_urls.add(result.url)
                unique_results.append(result)

        return unique_results

def create_external_search_layer() -> ExternalSearchLayer:
    """External Search Layer ìƒì„±ì"""
    return ExternalSearchLayer()

def process_external_search_layer(context: PipelineContext) -> PipelineContext:
    """External Search Layer ì²˜ë¦¬ í•¨ìˆ˜"""
    print(f"ğŸš€ EXTERNAL_SEARCH_LAYER ì‹œì‘ - {context.company_info.name}")
    print("=" * 60)
    
    search_layer = create_external_search_layer()

    # ë¹„ë™ê¸° ê²€ìƒ‰ ì‹¤í–‰
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    external_results = loop.run_until_complete(
        search_layer.search_external_sources(context.company_info.name)
    )

    context.external_search_results = external_results

    # ì²˜ë¦¬ ë‹¨ê³„ ê¸°ë¡
    context.processing_steps.append(
        f"EXTERNAL_SEARCH_LAYER: {len(external_results)}ê°œ ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ"
    )

    print(f"âœ… EXTERNAL_SEARCH_LAYER ì™„ë£Œ - {len(external_results)}ê°œ ê²°ê³¼")
    print("=" * 60)
    
    return context