"""
Layer 7: RISK ASSESSMENT LAYER
risk_evaluatorë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹œì¥, ê·œì œ, ê²½ìŸ, ì¬ë¬´ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ëŠ” ë ˆì´ì–´
"""
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import (
    RiskAssessment, RiskLevel, DocumentChunk, ExternalSearchResult,
    PipelineContext, CompanyInfo, AnalysisResult
)
from config import get_config

class BaseRiskEvaluator:
    """ë¦¬ìŠ¤í¬ í‰ê°€ê¸° ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, risk_category: str):
        self.risk_category = risk_category
        self.config = get_config()
        self.llm = ChatOpenAI(
            openai_api_key=self.config["model"].openai_api_key,
            temperature=0.1,
            model=self.config["model"].model_name  # ì˜ˆ: "gpt-4o-mini"
        )

    def evaluate(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> RiskAssessment:
        """ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        raise NotImplementedError

    def _calculate_risk_level(self, impact_score: float, probability: float) -> RiskLevel:
        """ë¦¬ìŠ¤í¬ ë ˆë²¨ ê³„ì‚°"""
        risk_score = impact_score * probability

        if risk_score >= 8.0:
            return RiskLevel.CRITICAL
        elif risk_score >= 6.0:
            return RiskLevel.HIGH
        elif risk_score >= 4.0:
            return RiskLevel.MEDIUM
        else:
            return RiskLevel.LOW

    def _create_analysis_context(
        self,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> str:
        """ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        context_parts = []

        # ê´€ë ¨ ë¬¸ì„œ ì •ë³´
        if documents:
            doc_summaries = []
            for doc in documents[:3]:
                doc_summaries.append(f"- {doc.content[:150]}...")
            context_parts.append("ê´€ë ¨ ë¬¸ì„œ:\n" + "\n".join(doc_summaries))

        # ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼
        if external_results:
            external_summaries = []
            for result in external_results[:2]:
                external_summaries.append(f"- {result.title}: {result.content[:100]}...")
            context_parts.append("ìµœì‹  ì •ë³´:\n" + "\n".join(external_summaries))

        # ë¶„ì„ ê²°ê³¼ ìš”ì•½
        if analysis_results:
            analysis_summaries = []
            for result in analysis_results:
                analysis_summaries.append(f"- {result.category}: {result.score}ì  ({result.grade})")
            context_parts.append("ë¶„ì„ ê²°ê³¼:\n" + "\n".join(analysis_summaries))

        return "\n\n".join(context_parts)

class MarketRiskEvaluator(BaseRiskEvaluator):
    """ì‹œì¥ ë¦¬ìŠ¤í¬ í‰ê°€ê¸°"""

    def __init__(self):
        super().__init__("market_risk")
        self.evaluation_prompt = PromptTemplate(
            input_variables=["company_name", "industry", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ì‹œì¥ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

íšŒì‚¬ëª…: {company_name}
ì—…ì¢…: {industry}

ê´€ë ¨ ì •ë³´:
{context}

ë‹¤ìŒ ì‹œì¥ ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ì‹œì¥ í¬í™”ë„ ë° ì„±ì¥ í•œê³„
2. ê²½ê¸° ë³€ë™ì— ëŒ€í•œ ë¯¼ê°ë„
3. ì†Œë¹„ì ì„ í˜¸ë„ ë³€í™” ë¦¬ìŠ¤í¬
4. ì‹ ê¸°ìˆ  ë“±ì¥ìœ¼ë¡œ ì¸í•œ ì‹œì¥ ë³€í™”
5. ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œ ì‹œ ì¥ë²½

í‰ê°€ ê¸°ì¤€:
- ì˜í–¥ë„(impact_score): 0-10ì  (10ì´ ê°€ì¥ ì‹¬ê°)
- ë°œìƒ í™•ë¥ (probability): 0-1 (1ì´ í™•ì‹¤)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "impact_score": 7.5,
    "probability": 0.6,
    "description": "ì‹œì¥ ë¦¬ìŠ¤í¬ ì„¤ëª…",
    "mitigation_strategies": ["ì™„í™” ì „ëµ 1", "ì™„í™” ì „ëµ 2"]
}}"""
        )

    def evaluate(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> RiskAssessment:
        """ì‹œì¥ ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰"""
        context = self._create_analysis_context(documents, external_results, analysis_results)

        try:
            response = self.llm.invoke(self.evaluation_prompt.format(
                company_name=company_info.name,
                industry=company_info.industry,
                context=context
            ))

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” RISK_ASSESSMENT_LAYER ({self.risk_category.upper()}) - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            import json
            risk_data = json.loads(response.content.strip())

            impact_score = risk_data.get("impact_score", 5.0)
            probability = risk_data.get("probability", 0.5)

            return RiskAssessment(
                category=self.risk_category,
                risk_level=self._calculate_risk_level(impact_score, probability),
                description=risk_data.get("description", ""),
                impact_score=impact_score,
                probability=probability,
                mitigation_strategies=risk_data.get("mitigation_strategies", [])
            )

        except Exception as e:
            return RiskAssessment(
                category=self.risk_category,
                risk_level=RiskLevel.MEDIUM,
                description=f"ì‹œì¥ ë¦¬ìŠ¤í¬ í‰ê°€ ì˜¤ë¥˜: {str(e)}",
                impact_score=5.0,
                probability=0.5,
                mitigation_strategies=[]
            )

class RegulatoryRiskEvaluator(BaseRiskEvaluator):
    """ê·œì œ ë¦¬ìŠ¤í¬ í‰ê°€ê¸°"""

    def __init__(self):
        super().__init__("regulatory_risk")
        self.evaluation_prompt = PromptTemplate(
            input_variables=["company_name", "industry", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ê·œì œ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

íšŒì‚¬ëª…: {company_name}
ì—…ì¢…: {industry}

ê´€ë ¨ ì •ë³´:
{context}

ë‹¤ìŒ ê·œì œ ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ê·œì œ ìœ„ë°˜ ê°€ëŠ¥ì„±
2. ë¯¸ë˜ ê·œì œ ê°•í™” ë¦¬ìŠ¤í¬
3. êµ­ê°€ë³„ ê·œì œ ì°¨ì´ë¡œ ì¸í•œ í™•ì¥ ì œì•½
4. ê°œì¸ì •ë³´ë³´í˜¸ ë° ë°ì´í„° ê´€ë ¨ ê·œì œ
5. ì—…ì¢…ë³„ íŠ¹í™” ê·œì œ ìš”êµ¬ì‚¬í•­

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "impact_score": 6.0,
    "probability": 0.4,
    "description": "ê·œì œ ë¦¬ìŠ¤í¬ ì„¤ëª…",
    "mitigation_strategies": ["ì™„í™” ì „ëµ 1", "ì™„í™” ì „ëµ 2"]
}}"""
        )

    def evaluate(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> RiskAssessment:
        """ê·œì œ ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰"""
        context = self._create_analysis_context(documents, external_results, analysis_results)

        try:
            response = self.llm.invoke(self.evaluation_prompt.format(
                company_name=company_info.name,
                industry=company_info.industry,
                context=context
            ))

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” RISK_ASSESSMENT_LAYER ({self.risk_category.upper()}) - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            import json
            risk_data = json.loads(response.content.strip())

            impact_score = risk_data.get("impact_score", 5.0)
            probability = risk_data.get("probability", 0.5)

            return RiskAssessment(
                category=self.risk_category,
                risk_level=self._calculate_risk_level(impact_score, probability),
                description=risk_data.get("description", ""),
                impact_score=impact_score,
                probability=probability,
                mitigation_strategies=risk_data.get("mitigation_strategies", [])
            )

        except Exception as e:
            return RiskAssessment(
                category=self.risk_category,
                risk_level=RiskLevel.MEDIUM,
                description=f"ê·œì œ ë¦¬ìŠ¤í¬ í‰ê°€ ì˜¤ë¥˜: {str(e)}",
                impact_score=5.0,
                probability=0.5,
                mitigation_strategies=[]
            )

class CompetitiveRiskEvaluator(BaseRiskEvaluator):
    """ê²½ìŸ ë¦¬ìŠ¤í¬ í‰ê°€ê¸°"""

    def __init__(self):
        super().__init__("competitive_risk")
        self.evaluation_prompt = PromptTemplate(
            input_variables=["company_name", "industry", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ê²½ìŸ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

íšŒì‚¬ëª…: {company_name}
ì—…ì¢…: {industry}

ê´€ë ¨ ì •ë³´:
{context}

ë‹¤ìŒ ê²½ìŸ ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ê¸°ì¡´ ëŒ€ê¸°ì—…ì˜ ì‹œì¥ ì§„ì… ìœ„í—˜
2. ì‹ ê·œ ê²½ìŸìì˜ ë“±ì¥ ê°€ëŠ¥ì„±
3. ëŒ€ì²´ì¬ ì¶œí˜„ ë¦¬ìŠ¤í¬
4. ê°€ê²© ê²½ìŸ ì‹¬í™” ìœ„í—˜
5. í•µì‹¬ ì¸ì¬ ìœ ì¶œ ë¦¬ìŠ¤í¬

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "impact_score": 8.0,
    "probability": 0.7,
    "description": "ê²½ìŸ ë¦¬ìŠ¤í¬ ì„¤ëª…",
    "mitigation_strategies": ["ì™„í™” ì „ëµ 1", "ì™„í™” ì „ëµ 2"]
}}"""
        )

    def evaluate(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> RiskAssessment:
        """ê²½ìŸ ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰"""
        context = self._create_analysis_context(documents, external_results, analysis_results)

        try:
            response = self.llm.invoke(self.evaluation_prompt.format(
                company_name=company_info.name,
                industry=company_info.industry,
                context=context
            ))

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” RISK_ASSESSMENT_LAYER ({self.risk_category.upper()}) - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            import json
            risk_data = json.loads(response.content.strip())

            impact_score = risk_data.get("impact_score", 5.0)
            probability = risk_data.get("probability", 0.5)

            return RiskAssessment(
                category=self.risk_category,
                risk_level=self._calculate_risk_level(impact_score, probability),
                description=risk_data.get("description", ""),
                impact_score=impact_score,
                probability=probability,
                mitigation_strategies=risk_data.get("mitigation_strategies", [])
            )

        except Exception as e:
            return RiskAssessment(
                category=self.risk_category,
                risk_level=RiskLevel.MEDIUM,
                description=f"ê²½ìŸ ë¦¬ìŠ¤í¬ í‰ê°€ ì˜¤ë¥˜: {str(e)}",
                impact_score=5.0,
                probability=0.5,
                mitigation_strategies=[]
            )

class FinancialRiskEvaluator(BaseRiskEvaluator):
    """ì¬ë¬´ ë¦¬ìŠ¤í¬ í‰ê°€ê¸°"""

    def __init__(self):
        super().__init__("financial_risk")
        self.evaluation_prompt = PromptTemplate(
            input_variables=["company_name", "industry", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ì¬ë¬´ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

íšŒì‚¬ëª…: {company_name}
ì—…ì¢…: {industry}

ê´€ë ¨ ì •ë³´:
{context}

ë‹¤ìŒ ì¬ë¬´ ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. í˜„ê¸ˆ ì†Œì§„ ìœ„í—˜ (burn rate vs runway)
2. ì¶”ê°€ íˆ¬ì ìœ ì¹˜ ì‹¤íŒ¨ ë¦¬ìŠ¤í¬
3. ìˆ˜ìµì„± ë‹¬ì„± ì§€ì—° ìœ„í—˜
4. ê³ ì •ë¹„ ë¶€ë‹´ ì¦ê°€ ë¦¬ìŠ¤í¬
5. í™˜ìœ¨ ë° ì´ììœ¨ ë³€ë™ ë¦¬ìŠ¤í¬

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "impact_score": 9.0,
    "probability": 0.5,
    "description": "ì¬ë¬´ ë¦¬ìŠ¤í¬ ì„¤ëª…",
    "mitigation_strategies": ["ì™„í™” ì „ëµ 1", "ì™„í™” ì „ëµ 2"]
}}"""
        )

    def evaluate(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> RiskAssessment:
        """ì¬ë¬´ ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰"""
        context = self._create_analysis_context(documents, external_results, analysis_results)

        try:
            response = self.llm.invoke(self.evaluation_prompt.format(
                company_name=company_info.name,
                industry=company_info.industry,
                context=context
            ))

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” RISK_ASSESSMENT_LAYER ({self.risk_category.upper()}) - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            import json
            risk_data = json.loads(response.content.strip())

            impact_score = risk_data.get("impact_score", 5.0)
            probability = risk_data.get("probability", 0.5)

            return RiskAssessment(
                category=self.risk_category,
                risk_level=self._calculate_risk_level(impact_score, probability),
                description=risk_data.get("description", ""),
                impact_score=impact_score,
                probability=probability,
                mitigation_strategies=risk_data.get("mitigation_strategies", [])
            )

        except Exception as e:
            return RiskAssessment(
                category=self.risk_category,
                risk_level=RiskLevel.MEDIUM,
                description=f"ì¬ë¬´ ë¦¬ìŠ¤í¬ í‰ê°€ ì˜¤ë¥˜: {str(e)}",
                impact_score=5.0,
                probability=0.5,
                mitigation_strategies=[]
            )

class TechnologyRiskEvaluator(BaseRiskEvaluator):
    """ê¸°ìˆ  ë¦¬ìŠ¤í¬ í‰ê°€ê¸°"""

    def __init__(self):
        super().__init__("technology_risk")
        self.evaluation_prompt = PromptTemplate(
            input_variables=["company_name", "industry", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ê¸°ìˆ  ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

íšŒì‚¬ëª…: {company_name}
ì—…ì¢…: {industry}

ê´€ë ¨ ì •ë³´:
{context}

ë‹¤ìŒ ê¸°ìˆ  ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. í•µì‹¬ ê¸°ìˆ ì˜ ë…¸í›„í™” ìœ„í—˜
2. ë³´ì•ˆ ì·¨ì•½ì  ë° ì‚¬ì´ë²„ ê³µê²© ë¦¬ìŠ¤í¬
3. ê¸°ìˆ  ì¸ì¬ ì´íƒˆ ìœ„í—˜
4. í”Œë«í¼ ì˜ì¡´ì„± ë¦¬ìŠ¤í¬
5. ìŠ¤ì¼€ì¼ë§ ì‹œ ê¸°ìˆ ì  í•œê³„

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "impact_score": 6.5,
    "probability": 0.4,
    "description": "ê¸°ìˆ  ë¦¬ìŠ¤í¬ ì„¤ëª…",
    "mitigation_strategies": ["ì™„í™” ì „ëµ 1", "ì™„í™” ì „ëµ 2"]
}}"""
        )

    def evaluate(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> RiskAssessment:
        """ê¸°ìˆ  ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰"""
        context = self._create_analysis_context(documents, external_results, analysis_results)

        try:
            response = self.llm.invoke(self.evaluation_prompt.format(
                company_name=company_info.name,
                industry=company_info.industry,
                context=context
            ))

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” RISK_ASSESSMENT_LAYER ({self.risk_category.upper()}) - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            import json
            risk_data = json.loads(response.content.strip())

            impact_score = risk_data.get("impact_score", 5.0)
            probability = risk_data.get("probability", 0.5)

            return RiskAssessment(
                category=self.risk_category,
                risk_level=self._calculate_risk_level(impact_score, probability),
                description=risk_data.get("description", ""),
                impact_score=impact_score,
                probability=probability,
                mitigation_strategies=risk_data.get("mitigation_strategies", [])
            )

        except Exception as e:
            return RiskAssessment(
                category=self.risk_category,
                risk_level=RiskLevel.MEDIUM,
                description=f"ê¸°ìˆ  ë¦¬ìŠ¤í¬ í‰ê°€ ì˜¤ë¥˜: {str(e)}",
                impact_score=5.0,
                probability=0.5,
                mitigation_strategies=[]
            )

class TeamRiskEvaluator(BaseRiskEvaluator):
    """íŒ€ ë¦¬ìŠ¤í¬ í‰ê°€ê¸°"""

    def __init__(self):
        super().__init__("team_risk")
        self.evaluation_prompt = PromptTemplate(
            input_variables=["company_name", "industry", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ íŒ€ ê´€ë ¨ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

íšŒì‚¬ëª…: {company_name}
ì—…ì¢…: {industry}

ê´€ë ¨ ì •ë³´:
{context}

ë‹¤ìŒ íŒ€ ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ì°½ì—…ì/í•µì‹¬ ì¸ì¬ ì´íƒˆ ìœ„í—˜
2. íŒ€ ë‚´ë¶€ ê°ˆë“± ë° ë¶„ì—´ ê°€ëŠ¥ì„±
3. í•µì‹¬ ê¸°ìˆ ì í™•ë³´ ì–´ë ¤ì›€
4. ì¡°ì§ ë¬¸í™” ë° ê´€ë¦¬ ì²´ê³„ ë¯¸ë¹„
5. ì„±ì¥ì— ë”°ë¥¸ ì¸ì¬ ê´€ë¦¬ ì–´ë ¤ì›€

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "impact_score": 8.5,
    "probability": 0.3,
    "description": "íŒ€ ë¦¬ìŠ¤í¬ ì„¤ëª…",
    "mitigation_strategies": ["ì™„í™” ì „ëµ 1", "ì™„í™” ì „ëµ 2"]
}}"""
        )

    def evaluate(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> RiskAssessment:
        """íŒ€ ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰"""
        context = self._create_analysis_context(documents, external_results, analysis_results)

        try:
            response = self.llm.invoke(self.evaluation_prompt.format(
                company_name=company_info.name,
                industry=company_info.industry,
                context=context
            ))

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” RISK_ASSESSMENT_LAYER ({self.risk_category.upper()}) - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            import json
            risk_data = json.loads(response.content.strip())

            impact_score = risk_data.get("impact_score", 5.0)
            probability = risk_data.get("probability", 0.5)

            return RiskAssessment(
                category=self.risk_category,
                risk_level=self._calculate_risk_level(impact_score, probability),
                description=risk_data.get("description", ""),
                impact_score=impact_score,
                probability=probability,
                mitigation_strategies=risk_data.get("mitigation_strategies", [])
            )

        except Exception as e:
            return RiskAssessment(
                category=self.risk_category,
                risk_level=RiskLevel.MEDIUM,
                description=f"íŒ€ ë¦¬ìŠ¤í¬ í‰ê°€ ì˜¤ë¥˜: {str(e)}",
                impact_score=5.0,
                probability=0.5,
                mitigation_strategies=[]
            )

class RiskEvaluator:
    """ë¦¬ìŠ¤í¬ í‰ê°€ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.risk_evaluators = {
            "market_risk": MarketRiskEvaluator(),
            "regulatory_risk": RegulatoryRiskEvaluator(),
            "competitive_risk": CompetitiveRiskEvaluator(),
            "financial_risk": FinancialRiskEvaluator(),
            "technology_risk": TechnologyRiskEvaluator(),
            "team_risk": TeamRiskEvaluator()
        }

    def evaluate_all_risks(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult],
        selected_risks: List[str] = None
    ) -> List[RiskAssessment]:
        """ëª¨ë“  ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰ (ë³‘ë ¬)"""

        if selected_risks is None:
            selected_risks = list(self.risk_evaluators.keys())

        # ì„ íƒëœ ë¦¬ìŠ¤í¬ í‰ê°€ê¸°ë“¤ë§Œ ì‹¤í–‰
        selected_evaluators = {
            name: evaluator for name, evaluator in self.risk_evaluators.items()
            if name in selected_risks
        }

        # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=len(selected_evaluators)) as executor:
            future_to_evaluator = {
                executor.submit(
                    evaluator.evaluate,
                    company_info, documents, external_results, analysis_results
                ): name
                for name, evaluator in selected_evaluators.items()
            }

            risk_assessments = []
            for future in future_to_evaluator:
                try:
                    result = future.result(timeout=60)  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
                    risk_assessments.append(result)
                except Exception as e:
                    evaluator_name = future_to_evaluator[future]
                    error_assessment = RiskAssessment(
                        category=evaluator_name,
                        risk_level=RiskLevel.MEDIUM,
                        description=f"{evaluator_name} í‰ê°€ ì‹¤íŒ¨: {str(e)}",
                        impact_score=5.0,
                        probability=0.5,
                        mitigation_strategies=[]
                    )
                    risk_assessments.append(error_assessment)

        return risk_assessments

    def calculate_overall_risk_level(self, risk_assessments: List[RiskAssessment]) -> RiskLevel:
        """ì „ì²´ ë¦¬ìŠ¤í¬ ë ˆë²¨ ê³„ì‚°"""
        if not risk_assessments:
            return RiskLevel.MEDIUM

        # ë¦¬ìŠ¤í¬ ë ˆë²¨ì„ ìˆ«ìë¡œ ë³€í™˜
        risk_level_values = {
            RiskLevel.LOW: 1,
            RiskLevel.MEDIUM: 2,
            RiskLevel.HIGH: 3,
            RiskLevel.CRITICAL: 4
        }

        # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ì˜í–¥ë„ì™€ í™•ë¥  ê³ ë ¤)
        total_weighted_risk = 0.0
        total_weight = 0.0

        for assessment in risk_assessments:
            risk_value = risk_level_values[assessment.risk_level]
            weight = assessment.impact_score * assessment.probability
            total_weighted_risk += risk_value * weight
            total_weight += weight

        if total_weight == 0:
            return RiskLevel.MEDIUM

        average_risk = total_weighted_risk / total_weight

        # í‰ê· ê°’ì„ ë¦¬ìŠ¤í¬ ë ˆë²¨ë¡œ ë³€í™˜
        if average_risk >= 3.5:
            return RiskLevel.CRITICAL
        elif average_risk >= 2.5:
            return RiskLevel.HIGH
        elif average_risk >= 1.5:
            return RiskLevel.MEDIUM
        else:
            return RiskLevel.LOW

class CompetitiveRiskEvaluator(BaseRiskEvaluator):
    """ê²½ìŸ ë¦¬ìŠ¤í¬ í‰ê°€ê¸° (ëˆ„ë½ëœ í´ë˜ìŠ¤ ì¶”ê°€)"""

    def __init__(self):
        super().__init__("competitive_risk")
        self.evaluation_prompt = PromptTemplate(
            input_variables=["company_name", "industry", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ê²½ìŸ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

íšŒì‚¬ëª…: {company_name}
ì—…ì¢…: {industry}

ê´€ë ¨ ì •ë³´:
{context}

ë‹¤ìŒ ê²½ìŸ ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ê¸°ì¡´ ëŒ€ê¸°ì—…ì˜ ì‹œì¥ ì§„ì… ìœ„í—˜
2. ì‹ ê·œ ê²½ìŸìì˜ ë“±ì¥ ê°€ëŠ¥ì„±
3. ëŒ€ì²´ì¬ ì¶œí˜„ ë¦¬ìŠ¤í¬
4. ê°€ê²© ê²½ìŸ ì‹¬í™” ìœ„í—˜
5. ì‹œì¥ ì ìœ ìœ¨ ê°ì†Œ ìœ„í—˜

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "impact_score": 7.0,
    "probability": 0.6,
    "description": "ê²½ìŸ ë¦¬ìŠ¤í¬ ì„¤ëª…",
    "mitigation_strategies": ["ì™„í™” ì „ëµ 1", "ì™„í™” ì „ëµ 2"]
}}"""
        )

    def evaluate(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        analysis_results: List[AnalysisResult]
    ) -> RiskAssessment:
        """ê²½ìŸ ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰"""
        context = self._create_analysis_context(documents, external_results, analysis_results)

        try:
            response = self.llm.invoke(self.evaluation_prompt.format(
                company_name=company_info.name,
                industry=company_info.industry,
                context=context
            ))

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” RISK_ASSESSMENT_LAYER ({self.risk_category.upper()}) - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            import json
            risk_data = json.loads(response.content.strip())

            impact_score = risk_data.get("impact_score", 5.0)
            probability = risk_data.get("probability", 0.5)

            return RiskAssessment(
                category=self.risk_category,
                risk_level=self._calculate_risk_level(impact_score, probability),
                description=risk_data.get("description", ""),
                impact_score=impact_score,
                probability=probability,
                mitigation_strategies=risk_data.get("mitigation_strategies", [])
            )

        except Exception as e:
            return RiskAssessment(
                category=self.risk_category,
                risk_level=RiskLevel.MEDIUM,
                description=f"ê²½ìŸ ë¦¬ìŠ¤í¬ í‰ê°€ ì˜¤ë¥˜: {str(e)}",
                impact_score=5.0,
                probability=0.5,
                mitigation_strategies=[]
            )

def create_risk_assessment_layer() -> RiskEvaluator:
    """Risk Assessment Layer ìƒì„±ì"""
    return RiskEvaluator()

def process_risk_assessment_layer(context: PipelineContext) -> PipelineContext:
    """Risk Assessment Layer ì²˜ë¦¬ í•¨ìˆ˜"""
    risk_evaluator = create_risk_assessment_layer()

    # ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰
    risk_assessments = risk_evaluator.evaluate_all_risks(
        company_info=context.company_info,
        documents=context.retrieved_documents,
        external_results=context.external_search_results,
        analysis_results=context.analysis_results
    )

    context.risk_assessments = risk_assessments

    # ì „ì²´ ë¦¬ìŠ¤í¬ ë ˆë²¨ ê³„ì‚°
    overall_risk_level = risk_evaluator.calculate_overall_risk_level(risk_assessments)

    # ì²˜ë¦¬ ë‹¨ê³„ ê¸°ë¡
    context.processing_steps.append(
        f"RISK_ASSESSMENT_LAYER: {len(risk_assessments)}ê°œ ë¦¬ìŠ¤í¬ í‰ê°€ ì™„ë£Œ, "
        f"ì „ì²´ ë¦¬ìŠ¤í¬: {overall_risk_level.value}"
    )

    return context