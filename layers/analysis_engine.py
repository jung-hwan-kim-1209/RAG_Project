"""
Layer 5: ANALYSIS ENGINE
7ê°œ ë¶„ì„ ì˜ì—­ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ëŠ” ë ˆì´ì–´
"""
import asyncio
import os
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import AnalysisResult, DocumentChunk, ExternalSearchResult, PipelineContext, CompanyInfo, GPTResponse
from config import get_config

class BaseAnalyzer:
    """ë¶„ì„ê¸° ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, analyzer_name: str):
        self.analyzer_name = analyzer_name
        self.config = get_config()
        self.llm = ChatOpenAI(
            openai_api_key=self.config["model"].openai_api_key,
            temperature=0.1,
            model=self.config["model"].model_name  # ì˜ˆ: "gpt-4o-mini"
        )

    def analyze(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        context: PipelineContext = None
    ) -> AnalysisResult:
        """ë¶„ì„ ì‹¤í–‰ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        raise NotImplementedError

    def _create_context_summary(
        self,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult]
    ) -> str:
        """ë¬¸ì„œì™€ ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        context_parts = []

        # ìƒìœ„ ë¬¸ì„œë“¤ ìš”ì•½
        if documents:
            doc_summaries = []
            for doc in documents[:5]:  # ìƒìœ„ 5ê°œ ë¬¸ì„œë§Œ
                doc_summaries.append(f"- {doc.content[:200]}...")
            context_parts.append("ê´€ë ¨ ë¬¸ì„œ ì •ë³´:\n" + "\n".join(doc_summaries))

        # ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
        if external_results:
            external_summaries = []
            for result in external_results[:3]:  # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ
                external_summaries.append(f"- {result.title}: {result.content[:150]}...")
            context_parts.append("ìµœì‹  ì •ë³´:\n" + "\n".join(external_summaries))

        return "\n\n".join(context_parts)

    def _calculate_grade(self, score: float) -> str:
        """ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        grade_thresholds = self.config["scoring"].grade_thresholds

        if score >= grade_thresholds["S"]:
            return "S"
        elif score >= grade_thresholds["A"]:
            return "A"
        elif score >= grade_thresholds["B"]:
            return "B"
        elif score >= grade_thresholds["C"]:
            return "C"
        else:
            return "D"

class GrowthAnalyzer(BaseAnalyzer):
    """ì„±ì¥ì„± ë¶„ì„ê¸°"""

    def __init__(self):
        super().__init__("growth_analysis")
        self.analysis_prompt = PromptTemplate(
            input_variables=["company_name", "company_info", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ì„±ì¥ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

íšŒì‚¬ ì •ë³´:
{company_info}

ê´€ë ¨ ìë£Œ:
{context}

ë‹¤ìŒ í•­ëª©ë“¤ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  0-100ì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”:
1. ë§¤ì¶œ ì„±ì¥ë¥ 
2. ì‹œì¥ í™•ì¥ ê°€ëŠ¥ì„±
3. ê³ ê° ì¦ê°€ìœ¨
4. ì œí’ˆ/ì„œë¹„ìŠ¤ í™•ì¥ì„±
5. ì‹œì¥ ì ìœ ìœ¨ ì¦ê°€ ì ì¬ë ¥

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "score": 85,
    "summary": "ì„±ì¥ì„± ìš”ì•½",
    "detailed_analysis": "ìƒì„¸ ë¶„ì„ ë‚´ìš©",
    "key_strengths": ["ê°•ì 1", "ê°•ì 2"],
    "key_weaknesses": ["ì•½ì 1", "ì•½ì 2"],
    "supporting_evidence": ["ê·¼ê±°1", "ê·¼ê±°2"]
}}"""
        )

    def analyze(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        context: PipelineContext = None
    ) -> AnalysisResult:
        """ì„±ì¥ì„± ë¶„ì„ ì‹¤í–‰"""
        context_summary = self._create_context_summary(documents, external_results)
        company_info_text = f"ì—…ì¢…: {company_info.industry}, ì„¤ë¦½ë…„ë„: {company_info.founded_year}, ë³¸ì‚¬: {company_info.headquarters}"

        try:
            formatted_prompt = self.analysis_prompt.format(
                company_name=company_info.name,
                company_info=company_info_text,
                context=context_summary
            )
            
            response = self.llm.invoke(formatted_prompt)

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” {self.analyzer_name.upper()} - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            # GPT ì‘ë‹µì„ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            if context:
                gpt_response = GPTResponse(
                    layer_name="ANALYSIS_ENGINE",
                    analyzer_name=self.analyzer_name,
                    prompt=formatted_prompt,
                    response=response.content
                )
                context.gpt_responses.append(gpt_response)

            import json
            result_data = json.loads(response.content.strip())

            return AnalysisResult(
                category=self.analyzer_name,
                score=result_data.get("score", 50.0),
                grade=self._calculate_grade(result_data.get("score", 50.0)),
                summary=result_data.get("summary", ""),
                detailed_analysis=result_data.get("detailed_analysis", ""),
                key_strengths=result_data.get("key_strengths", []),
                key_weaknesses=result_data.get("key_weaknesses", []),
                supporting_evidence=result_data.get("supporting_evidence", [])
            )

        except Exception as e:
            # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return AnalysisResult(
                category=self.analyzer_name,
                score=50.0,
                grade="C",
                summary="ì„±ì¥ì„± ë¶„ì„ ì˜¤ë¥˜",
                detailed_analysis=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                key_strengths=[],
                key_weaknesses=[],
                supporting_evidence=[]
            )

class BusinessModelAnalyzer(BaseAnalyzer):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„ê¸°"""

    def __init__(self):
        super().__init__("business_model_analysis")
        self.analysis_prompt = PromptTemplate(
            input_variables=["company_name", "company_info", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

íšŒì‚¬ ì •ë³´:
{company_info}

ê´€ë ¨ ìë£Œ:
{context}

ë‹¤ìŒ í•­ëª©ë“¤ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  0-100ì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”:
1. ìˆ˜ìµ ëª¨ë¸ì˜ ì§€ì†ê°€ëŠ¥ì„±
2. ê³ ê° íšë“ ë¹„ìš© vs ê³ ê° ìƒì•  ê°€ì¹˜
3. ì‹œì¥ ì§„ì… ì¥ë²½
4. ê²½ìŸ ìš°ìœ„ ìš”ì†Œ
5. ìˆ˜ìµí™” êµ¬ì¡°ì˜ ëª…í™•ì„±

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "score": 75,
    "summary": "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ìš”ì•½",
    "detailed_analysis": "ìƒì„¸ ë¶„ì„ ë‚´ìš©",
    "key_strengths": ["ê°•ì 1", "ê°•ì 2"],
    "key_weaknesses": ["ì•½ì 1", "ì•½ì 2"],
    "supporting_evidence": ["ê·¼ê±°1", "ê·¼ê±°2"]
}}"""
        )

    def analyze(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        context: PipelineContext = None
    ) -> AnalysisResult:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„ ì‹¤í–‰"""
        context_summary = self._create_context_summary(documents, external_results)
        company_info_text = f"ì—…ì¢…: {company_info.industry}, ì„¤ëª…: {company_info.description}"

        try:
            formatted_prompt = self.analysis_prompt.format(
                company_name=company_info.name,
                company_info=company_info_text,
                context=context_summary
            )
            
            response = self.llm.invoke(formatted_prompt)

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” {self.analyzer_name.upper()} - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            # GPT ì‘ë‹µì„ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            if context:
                gpt_response = GPTResponse(
                    layer_name="ANALYSIS_ENGINE",
                    analyzer_name=self.analyzer_name,
                    prompt=formatted_prompt,
                    response=response.content
                )
                context.gpt_responses.append(gpt_response)

            import json
            result_data = json.loads(response.content.strip())

            return AnalysisResult(
                category=self.analyzer_name,
                score=result_data.get("score", 50.0),
                grade=self._calculate_grade(result_data.get("score", 50.0)),
                summary=result_data.get("summary", ""),
                detailed_analysis=result_data.get("detailed_analysis", ""),
                key_strengths=result_data.get("key_strengths", []),
                key_weaknesses=result_data.get("key_weaknesses", []),
                supporting_evidence=result_data.get("supporting_evidence", [])
            )

        except Exception as e:
            return AnalysisResult(
                category=self.analyzer_name,
                score=50.0,
                grade="C",
                summary="ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„ ì˜¤ë¥˜",
                detailed_analysis=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                key_strengths=[],
                key_weaknesses=[],
                supporting_evidence=[]
            )

class TechSecurityAnalyzer(BaseAnalyzer):
    """ê¸°ìˆ ë ¥/ë³´ì•ˆì„± ë¶„ì„ê¸°"""

    def __init__(self):
        super().__init__("tech_security_analysis")
        self.analysis_prompt = PromptTemplate(
            input_variables=["company_name", "company_info", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ê¸°ìˆ ë ¥ê³¼ ë³´ì•ˆì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

íšŒì‚¬ ì •ë³´:
{company_info}

ê´€ë ¨ ìë£Œ:
{context}

ë‹¤ìŒ í•­ëª©ë“¤ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  0-100ì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”:
1. í•µì‹¬ ê¸°ìˆ ì˜ ì°¨ë³„ì„±
2. íŠ¹í—ˆ ë° ì§€ì ì¬ì‚°ê¶Œ
3. ê°œë°œíŒ€ì˜ ê¸°ìˆ  ì—­ëŸ‰
4. ë³´ì•ˆ ì²´ê³„ ë° ë°ì´í„° ë³´í˜¸
5. ê¸°ìˆ  í˜ì‹ ì„± ë° ë¯¸ë˜ ëŒ€ì‘ë ¥

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "score": 80,
    "summary": "ê¸°ìˆ ë ¥/ë³´ì•ˆì„± ìš”ì•½",
    "detailed_analysis": "ìƒì„¸ ë¶„ì„ ë‚´ìš©",
    "key_strengths": ["ê°•ì 1", "ê°•ì 2"],
    "key_weaknesses": ["ì•½ì 1", "ì•½ì 2"],
    "supporting_evidence": ["ê·¼ê±°1", "ê·¼ê±°2"]
}}"""
        )

    def analyze(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        context: PipelineContext = None
    ) -> AnalysisResult:
        """ê¸°ìˆ ë ¥/ë³´ì•ˆì„± ë¶„ì„ ì‹¤í–‰"""
        context_summary = self._create_context_summary(documents, external_results)
        company_info_text = f"ì—…ì¢…: {company_info.industry}, ì„¤ëª…: {company_info.description}"

        try:
            formatted_prompt = self.analysis_prompt.format(
                company_name=company_info.name,
                company_info=company_info_text,
                context=context_summary
            )
            
            response = self.llm.invoke(formatted_prompt)

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” {self.analyzer_name.upper()} - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            # GPT ì‘ë‹µì„ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            if context:
                gpt_response = GPTResponse(
                    layer_name="ANALYSIS_ENGINE",
                    analyzer_name=self.analyzer_name,
                    prompt=formatted_prompt,
                    response=response.content
                )
                context.gpt_responses.append(gpt_response)

            import json
            result_data = json.loads(response.content.strip())

            return AnalysisResult(
                category=self.analyzer_name,
                score=result_data.get("score", 50.0),
                grade=self._calculate_grade(result_data.get("score", 50.0)),
                summary=result_data.get("summary", ""),
                detailed_analysis=result_data.get("detailed_analysis", ""),
                key_strengths=result_data.get("key_strengths", []),
                key_weaknesses=result_data.get("key_weaknesses", []),
                supporting_evidence=result_data.get("supporting_evidence", [])
            )

        except Exception as e:
            return AnalysisResult(
                category=self.analyzer_name,
                score=50.0,
                grade="C",
                summary="ê¸°ìˆ ë ¥/ë³´ì•ˆì„± ë¶„ì„ ì˜¤ë¥˜",
                detailed_analysis=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                key_strengths=[],
                key_weaknesses=[],
                supporting_evidence=[]
            )

class FinancialHealthAnalyzer(BaseAnalyzer):
    """ì¬ë¬´ê±´ì „ì„± ë¶„ì„ê¸°"""

    def __init__(self):
        super().__init__("financial_health_analysis")
        self.analysis_prompt = PromptTemplate(
            input_variables=["company_name", "company_info", "context"],
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì˜ ì¬ë¬´ê±´ì „ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

íšŒì‚¬ ì •ë³´:
{company_info}

ê´€ë ¨ ìë£Œ:
{context}

ë‹¤ìŒ í•­ëª©ë“¤ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  0-100ì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”:
1. í˜„ê¸ˆ ë³´ìœ  í˜„í™© ë° ìš´ì˜ ìê¸ˆ
2. ë§¤ì¶œ ì„±ì¥ë¥  ë° ìˆ˜ìµì„±
3. íˆ¬ì ìœ ì¹˜ ì´ë ¥ ë° ë°¸ë¥˜ì—ì´ì…˜
4. ë¹„ìš© êµ¬ì¡° ë° íš¨ìœ¨ì„±
5. ì¬ë¬´ ë¦¬ìŠ¤í¬ ìš”ì†Œ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "score": 70,
    "summary": "ì¬ë¬´ê±´ì „ì„± ìš”ì•½",
    "detailed_analysis": "ìƒì„¸ ë¶„ì„ ë‚´ìš©",
    "key_strengths": ["ê°•ì 1", "ê°•ì 2"],
    "key_weaknesses": ["ì•½ì 1", "ì•½ì 2"],
    "supporting_evidence": ["ê·¼ê±°1", "ê·¼ê±°2"]
}}"""
        )

    def analyze(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        context: PipelineContext = None
    ) -> AnalysisResult:
        """ì¬ë¬´ê±´ì „ì„± ë¶„ì„ ì‹¤í–‰"""
        context_summary = self._create_context_summary(documents, external_results)
        company_info_text = f"ì—…ì¢…: {company_info.industry}, ì„¤ë¦½ë…„ë„: {company_info.founded_year}"

        try:
            formatted_prompt = self.analysis_prompt.format(
                company_name=company_info.name,
                company_info=company_info_text,
                context=context_summary
            )
            
            response = self.llm.invoke(formatted_prompt)

            # GPT ì‘ë‹µì„ í„°ë¯¸ë„ì— ì¶œë ¥
            print(f"\nğŸ” {self.analyzer_name.upper()} - GPT ì‘ë‹µ:")
            print("=" * 60)
            print(response.content)
            print("=" * 60)

            # GPT ì‘ë‹µì„ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            if context:
                gpt_response = GPTResponse(
                    layer_name="ANALYSIS_ENGINE",
                    analyzer_name=self.analyzer_name,
                    prompt=formatted_prompt,
                    response=response.content
                )
                context.gpt_responses.append(gpt_response)

            import json
            result_data = json.loads(response.content.strip())

            return AnalysisResult(
                category=self.analyzer_name,
                score=result_data.get("score", 50.0),
                grade=self._calculate_grade(result_data.get("score", 50.0)),
                summary=result_data.get("summary", ""),
                detailed_analysis=result_data.get("detailed_analysis", ""),
                key_strengths=result_data.get("key_strengths", []),
                key_weaknesses=result_data.get("key_weaknesses", []),
                supporting_evidence=result_data.get("supporting_evidence", [])
            )

        except Exception as e:
            return AnalysisResult(
                category=self.analyzer_name,
                score=50.0,
                grade="C",
                summary="ì¬ë¬´ê±´ì „ì„± ë¶„ì„ ì˜¤ë¥˜",
                detailed_analysis=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                key_strengths=[],
                key_weaknesses=[],
                supporting_evidence=[]
            )




class AnalysisEngine:
    """ë¶„ì„ ì—”ì§„ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.analyzers = {
            "growth_analysis": GrowthAnalyzer(),
            "business_model_analysis": BusinessModelAnalyzer(),
            "tech_security_analysis": TechSecurityAnalyzer(),
            "financial_health_analysis": FinancialHealthAnalyzer()
        }

    def run_parallel_analysis(
        self,
        company_info: CompanyInfo,
        documents: List[DocumentChunk],
        external_results: List[ExternalSearchResult],
        selected_analyses: List[str] = None,
        context: PipelineContext = None
    ) -> List[AnalysisResult]:
        """ë³‘ë ¬ë¡œ ë¶„ì„ ì‹¤í–‰"""

        if selected_analyses is None:
            selected_analyses = list(self.analyzers.keys())

        # ì„ íƒëœ ë¶„ì„ê¸°ë“¤ë§Œ ì‹¤í–‰
        selected_analyzers = {
            name: analyzer for name, analyzer in self.analyzers.items()
            if name in selected_analyses
        }

        # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=len(selected_analyzers)) as executor:
            future_to_analyzer = {
                executor.submit(
                    analyzer.analyze, company_info, documents, external_results, context
                ): name
                for name, analyzer in selected_analyzers.items()
            }

            results = []
            for future in future_to_analyzer:
                try:
                    timeout_seconds = int(os.getenv("ANALYSIS_TIMEOUT_SECONDS", "60"))
                    result = future.result(timeout=timeout_seconds)
                    results.append(result)
                except Exception as e:
                    analyzer_name = future_to_analyzer[future]
                    error_result = AnalysisResult(
                        category=analyzer_name,
                        score=0.0,
                        grade="D",
                        summary=f"{analyzer_name} ë¶„ì„ ì‹¤íŒ¨",
                        detailed_analysis=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                        key_strengths=[],
                        key_weaknesses=[],
                        supporting_evidence=[]
                    )
                    results.append(error_result)

        return results

def create_analysis_engine() -> AnalysisEngine:
    """Analysis Engine ìƒì„±ì"""
    return AnalysisEngine()

def process_analysis_engine(context: PipelineContext) -> PipelineContext:
    """Analysis Engine ì²˜ë¦¬ í•¨ìˆ˜"""
    analysis_engine = create_analysis_engine()

    # í‰ê°€ ìœ í˜•ì— ë”°ë¥¸ ë¶„ì„ ì„ íƒ
    evaluation_type = context.parsed_input.evaluation_type
    selected_analyses = []

    # ì „ì²´ í‰ê°€ì¸ ê²½ìš° ëª¨ë“  ë¶„ì„ ì‹¤í–‰
    if evaluation_type.value == "ì „ì²´ í‰ê°€":
        selected_analyses = list(analysis_engine.analyzers.keys())
    else:
        # íŠ¹ì • í‰ê°€ ìœ í˜•ì— ë”°ë¥¸ ë¶„ì„ ì„ íƒ
        analysis_mapping = {
            "ì„±ì¥ì„± ë¶„ì„": ["growth_analysis", "business_model_analysis"],
            "ì¬ë¬´ ë¶„ì„": ["financial_health_analysis", "growth_analysis"],
            "ê¸°ìˆ  ë¶„ì„": ["tech_security_analysis", "business_model_analysis"],
            "ë¦¬ìŠ¤í¬ ë¶„ì„": ["financial_health_analysis", "tech_security_analysis"]
        }
        selected_analyses = analysis_mapping.get(evaluation_type.value, ["growth_analysis"])

    # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
    analysis_results = analysis_engine.run_parallel_analysis(
        company_info=context.company_info,
        documents=context.retrieved_documents,
        external_results=context.external_search_results,
        selected_analyses=selected_analyses,
        context=context
    )

    context.analysis_results = analysis_results

    # ì²˜ë¦¬ ë‹¨ê³„ ê¸°ë¡
    context.processing_steps.append(
        f"ANALYSIS_ENGINE: {len(analysis_results)}ê°œ ë¶„ì„ ì™„ë£Œ (ë³‘ë ¬ ì‹¤í–‰) - 4ê°œ ë¶„ì„ê¸° ì‚¬ìš©"
    )

    return context