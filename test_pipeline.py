"""
AI ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì í‰ê°€ ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
"""
import os
import unittest
from unittest.mock import Mock, patch
from datetime import datetime

# í…ŒìŠ¤íŠ¸ìš© í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
from dotenv import load_dotenv
load_dotenv()

# í…ŒìŠ¤íŠ¸ìš© í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ê¸°ë³¸ê°’ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ)
if not os.getenv("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = "test_key"
if not os.getenv("HF_TOKEN"):
    os.environ["HF_TOKEN"] = "test_hf_token"

from models import (
    CompanyInfo, ParsedInput, EvaluationType, DocumentChunk,
    ExternalSearchResult, AnalysisResult, RiskAssessment, RiskLevel,
    UnicornScore, InvestmentReport, InvestmentRecommendation, PipelineContext
)
from pipeline import InvestmentEvaluationPipeline
from layers.input_layer import InputParser
from layers.analysis_engine import GrowthAnalyzer
from layers.scoring_engine import UnicornScoreCalculator

class TestModels(unittest.TestCase):
    """ë°ì´í„° ëª¨ë¸ í…ŒìŠ¤íŠ¸"""

    def test_company_info_creation(self):
        """CompanyInfo ìƒì„± í…ŒìŠ¤íŠ¸"""
        company = CompanyInfo(
            name="ì—ì´ì  ê¸€ë¡œë²Œ",
            industry="í•€í…Œí¬",
            founded_year=2013,
            headquarters="ì„œìš¸"
        )
        self.assertEqual(company.name, "ì—ì´ì  ê¸€ë¡œë²Œ")
        self.assertEqual(company.industry, "í•€í…Œí¬")

    def test_analysis_result_creation(self):
        """AnalysisResult ìƒì„± í…ŒìŠ¤íŠ¸"""
        result = AnalysisResult(
            category="growth_analysis",
            score=85.0,
            grade="A",
            summary="ìš°ìˆ˜í•œ ì„±ì¥ì„±",
            detailed_analysis="ìƒì„¸ ë¶„ì„ ë‚´ìš©",
            key_strengths=["ê°•ë ¥í•œ ì„±ì¥", "ì‹œì¥ í™•ì¥"],
            key_weaknesses=["ê²½ìŸ ì‹¬í™”"]
        )
        self.assertEqual(result.score, 85.0)
        self.assertEqual(result.grade, "A")

    def test_risk_assessment_creation(self):
        """RiskAssessment ìƒì„± í…ŒìŠ¤íŠ¸"""
        risk = RiskAssessment(
            category="market_risk",
            risk_level=RiskLevel.MEDIUM,
            description="ì‹œì¥ ìœ„í—˜ ì¤‘ê°„ ìˆ˜ì¤€",
            impact_score=6.0,
            probability=0.4
        )
        self.assertEqual(risk.risk_level, RiskLevel.MEDIUM)
        self.assertEqual(risk.impact_score, 6.0)

class TestInputLayer(unittest.TestCase):
    """ì…ë ¥ ë ˆì´ì–´ í…ŒìŠ¤íŠ¸"""

    def setUp(self):
        self.input_parser = InputParser()

    @patch('layers.input_layer.ChatOpenAI')
    def test_simple_parsing(self, mock_chat_openai):
        """ê°„ë‹¨í•œ ì…ë ¥ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        # Mock LLM ì‘ë‹µ
        mock_llm_instance = Mock()
        mock_response = Mock()
        mock_response.content = '{"company_name": "ì—ì´ì  ê¸€ë¡œë²Œ", "evaluation_type": "ì „ì²´ í‰ê°€", "specific_focus_areas": [], "additional_requirements": ""}'
        mock_llm_instance.invoke.return_value = mock_response
        mock_chat_openai.return_value = mock_llm_instance

        # ìƒˆë¡œìš´ InputParser ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Mockì´ ì ìš©ëœ ìƒíƒœì—ì„œ)
        parser = InputParser()
        result = parser.parse("ì—ì´ì  ê¸€ë¡œë²Œì˜ íˆ¬ì ê°€ì¹˜ë¥¼ í‰ê°€í•´ì¤˜")

        self.assertEqual(result.company_name, "ì—ì´ì  ê¸€ë¡œë²Œ")
        self.assertEqual(result.evaluation_type, EvaluationType.FULL_EVALUATION)

    def test_fallback_parsing(self):
        """ë°±ì—… íŒŒì‹± ë¡œì§ í…ŒìŠ¤íŠ¸"""
        result = self.input_parser._fallback_parsing("ì¹´ì¹´ì˜¤ ì„±ì¥ì„± ë¶„ì„í•´ì¤˜")

        self.assertEqual(result.company_name, "ì¹´ì¹´ì˜¤")
        self.assertEqual(result.evaluation_type, EvaluationType.GROWTH_ANALYSIS)

    def test_company_info_extraction(self):
        """íšŒì‚¬ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        company_info = self.input_parser.extract_company_info("ì—ì´ì  ê¸€ë¡œë²Œ")

        self.assertEqual(company_info.name, "ì—ì´ì  ê¸€ë¡œë²Œ")
        # ì•Œë ¤ì§„ ê¸°ì—…ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ í™•ì¸
        if company_info.industry:
            self.assertEqual(company_info.industry, "í•€í…Œí¬")

class TestScoringEngine(unittest.TestCase):
    """ì ìˆ˜ ì—”ì§„ í…ŒìŠ¤íŠ¸"""

    def setUp(self):
        self.calculator = UnicornScoreCalculator()

    def test_grade_calculation(self):
        """ë“±ê¸‰ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        self.assertEqual(self.calculator.calculate_grade(95.0), "S")
        self.assertEqual(self.calculator.calculate_grade(85.0), "A")
        self.assertEqual(self.calculator.calculate_grade(75.0), "B")
        self.assertEqual(self.calculator.calculate_grade(65.0), "C")
        self.assertEqual(self.calculator.calculate_grade(45.0), "D")

    def test_weighted_score_calculation(self):
        """ê°€ì¤‘ì¹˜ ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        analysis_results = [
            AnalysisResult("growth_analysis", 80.0, "B", "", "", [], []),
            AnalysisResult("business_model_analysis", 85.0, "A", "", "", [], []),
            AnalysisResult("tech_security_analysis", 90.0, "A", "", "", [], [])
        ]

        category_scores, weighted_scores = self.calculator.calculate_weighted_score(analysis_results)

        self.assertEqual(category_scores["growth_analysis"], 80.0)
        self.assertTrue(weighted_scores["growth_analysis"] > 0)

class TestPipeline(unittest.TestCase):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

    def setUp(self):
        self.pipeline = InvestmentEvaluationPipeline()

    @patch('layers.input_layer.ChatOpenAI')
    @patch('layers.knowledge_base_layer.Chroma')
    @patch('layers.external_search_layer.WebSearchAgent')
    def test_partial_pipeline_execution(self, mock_search, mock_chroma, mock_chat_openai):
        """ë¶€ë¶„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì •
        mock_llm = Mock()
        mock_response = Mock()
        mock_response.content = '{"company_name": "ì—ì´ì  ê¸€ë¡œë²Œ", "evaluation_type": "ì „ì²´ í‰ê°€", "specific_focus_areas": [], "additional_requirements": ""}'
        mock_llm.invoke.return_value = mock_response
        mock_chat_openai.return_value = mock_llm

        # í…ŒìŠ¤íŠ¸ìš© ì»¨í…ìŠ¤íŠ¸ ì‹¤í–‰
        context = self.pipeline.execute_partial_pipeline(
            user_input="ì—ì´ì  ê¸€ë¡œë²Œ íˆ¬ì í‰ê°€",
            start_layer="INPUT_LAYER",
            end_layer="INPUT_LAYER"
        )

        self.assertIsNotNone(context.parsed_input)
        self.assertTrue(len(context.processing_steps) > 0)

class TestQualityMetrics(unittest.TestCase):
    """í’ˆì§ˆ ì§€í‘œ í…ŒìŠ¤íŠ¸"""

    def test_relevance_calculation(self):
        """ê´€ë ¨ì„± ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        from layers.quality_check_layer import RelevanceChecker

        checker = RelevanceChecker()

        # ê¸°ë³¸ ê´€ë ¨ì„± ê³„ì‚° í…ŒìŠ¤íŠ¸
        company_name = "ì—ì´ì  ê¸€ë¡œë²Œ"
        report = Mock()
        report.company_info.name = "ì—ì´ì  ê¸€ë¡œë²Œ"
        report.analysis_results = [Mock()]
        report.risk_assessments = [Mock()]

        relevance = checker._calculate_basic_relevance(company_name, report)

        self.assertTrue(0.0 <= relevance <= 1.0)
        self.assertGreater(relevance, 0.5)  # íšŒì‚¬ëª… ì¼ì¹˜ë¡œ ì¸í•œ ì ìˆ˜

class TestEndToEndScenarios(unittest.TestCase):
    """End-to-End ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""

    def setUp(self):
        self.test_queries = [
            "ì—ì´ì  ê¸€ë¡œë²Œì˜ íˆ¬ì ê°€ì¹˜ë¥¼ í‰ê°€í•´ì¤˜",
            "ì—ì´ì  ê¸€ë¡œë²Œì˜ ì„±ì¥ì„± ë¶„ì„",
            "ì—ì´ì  ê¸€ë¡œë²Œì˜ ë¦¬ìŠ¤í¬ í‰ê°€",
            "ì—ì´ì  ê¸€ë¡œë²Œì˜ ê¸°ìˆ ë ¥ ë¶„ì„"
        ]

    def test_query_parsing_scenarios(self):
        """ë‹¤ì–‘í•œ ì¿¼ë¦¬ íŒŒì‹± ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        parser = InputParser()

        for query in self.test_queries:
            with self.subTest(query=query):
                try:
                    result = parser._fallback_parsing(query)
                    self.assertIsNotNone(result.company_name)
                    self.assertIn(result.evaluation_type, list(EvaluationType))
                except Exception as e:
                    self.fail(f"Query parsing failed for '{query}': {e}")

class TestErrorHandling(unittest.TestCase):
    """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""

    def test_missing_api_key(self):
        """API í‚¤ ëˆ„ë½ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ì œê±°
        original_key = os.environ.get("OPENAI_API_KEY")
        if "OPENAI_API_KEY" in os.environ:
            del os.environ["OPENAI_API_KEY"]
        
        try:
            # ModelConfig ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ ì§ì ‘ í™˜ê²½ë³€ìˆ˜ í™•ì¸
            from config import ModelConfig
            
            # í™˜ê²½ë³€ìˆ˜ê°€ ì‹¤ì œë¡œ ì‚­ì œë˜ì—ˆëŠ”ì§€ í™•ì¸
            self.assertIsNone(os.environ.get("OPENAI_API_KEY"))
            
            # ModelConfigì˜ ê¸°ë³¸ê°’ ë¡œì§ì„ ì§ì ‘ í…ŒìŠ¤íŠ¸
            test_key = os.getenv("OPENAI_API_KEY", "")
            self.assertEqual(test_key, "")
            
        finally:
            # API í‚¤ ë³µì›
            if original_key:
                os.environ["OPENAI_API_KEY"] = original_key

    def test_empty_input_handling(self):
        """ë¹ˆ ì…ë ¥ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        parser = InputParser()
        result = parser._fallback_parsing("")

        self.assertEqual(result.company_name, "")
        self.assertEqual(result.evaluation_type, EvaluationType.FULL_EVALUATION)

class TestIntegration(unittest.TestCase):
    """í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_mock_pipeline_flow(self):
        """Mockì„ ì‚¬ìš©í•œ íŒŒì´í”„ë¼ì¸ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ìš© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = PipelineContext(
            parsed_input=ParsedInput(
                company_name="ì—ì´ì  ê¸€ë¡œë²Œ",
                evaluation_type=EvaluationType.FULL_EVALUATION
            ),
            company_info=CompanyInfo(name="ì—ì´ì  ê¸€ë¡œë²Œ", industry="í•€í…Œí¬"),
            retrieved_documents=[
                DocumentChunk("í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ë‚´ìš©", "RAG\RAG_Project\data\documents\company_profiles\rag.pdf")
            ],
            external_search_results=[
                ExternalSearchResult("ì—ì´ì  ê¸€ë¡œë²Œ ë‰´ìŠ¤", "ì—ì´ì  ê¸€ë¡œë²Œ ê´€ë ¨ ë‰´ìŠ¤ ë‚´ìš©", "news_source", "http://example.com")
            ],
            analysis_results=[
                AnalysisResult("growth_analysis", 85.0, "A", "ì„±ì¥ì„± ìš°ìˆ˜", "ìƒì„¸ ë¶„ì„", ["ê°•ì 1"], ["ì•½ì 1"])
            ],
            risk_assessments=[
                RiskAssessment("market_risk", RiskLevel.LOW, "ì‹œì¥ ë¦¬ìŠ¤í¬ ë‚®ìŒ", 3.0, 0.3)
            ]
        )

        # ê° ë‹¨ê³„ë³„ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
        self.assertEqual(context.company_info.name, "ì—ì´ì  ê¸€ë¡œë²Œ")
        self.assertEqual(len(context.analysis_results), 1)
        self.assertEqual(len(context.risk_assessments), 1)
        self.assertEqual(context.analysis_results[0].score, 85.0)

def create_test_suite():
    """í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„±"""
    test_suite = unittest.TestSuite()

    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ë“¤
    loader = unittest.TestLoader()
    test_suite.addTest(loader.loadTestsFromTestCase(TestModels))
    test_suite.addTest(loader.loadTestsFromTestCase(TestInputLayer))
    test_suite.addTest(loader.loadTestsFromTestCase(TestScoringEngine))
    test_suite.addTest(loader.loadTestsFromTestCase(TestQualityMetrics))
    test_suite.addTest(loader.loadTestsFromTestCase(TestEndToEndScenarios))
    test_suite.addTest(loader.loadTestsFromTestCase(TestErrorHandling))
    test_suite.addTest(loader.loadTestsFromTestCase(TestIntegration))

    # íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆì–´ ì„ íƒì ìœ¼ë¡œ)
    # test_suite.addTest(unittest.makeSuite(TestPipeline))

    return test_suite

def run_tests():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª AI ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì í‰ê°€ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    print("=" * 60)

    test_suite = create_test_suite()
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)

    print("=" * 60)
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"   ì‹¤í–‰ëœ í…ŒìŠ¤íŠ¸: {result.testsRun}")
    print(f"   ì‹¤íŒ¨: {len(result.failures)}")
    print(f"   ì—ëŸ¬: {len(result.errors)}")

    if result.failures:
        print("\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
        for test, traceback in result.failures:
            print(f"   - {test}: {traceback}")

    if result.errors:
        print("\nğŸ”¥ ì—ëŸ¬ê°€ ë°œìƒí•œ í…ŒìŠ¤íŠ¸:")
        for test, traceback in result.errors:
            print(f"   - {test}: {traceback}")

    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun
    print(f"\nâœ¨ ì„±ê³µë¥ : {success_rate:.1%}")

    return result.wasSuccessful()

if __name__ == '__main__':
    success = run_tests()
    exit(0 if success else 1)